{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix dataset without user data\n",
    "During a previous hackathon, we were given a csv containing netflix data. I only had an hour and a half to produce some code. I decided to see what I could do given more time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ngram\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH HANDLING:\n",
    "def get_path(relative_path: str) -> str:\n",
    "    try:\n",
    "        basedir = os.path.dirname(os.path.abspath(__file__)) + \"\\\\\"\n",
    "    except NameError:\n",
    "        basedir = os.getcwd() + \"\\\\\"\n",
    "    return os.path.join(basedir, relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20840047, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>category</th>\n",
       "      <th>primaryName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0177707</td>\n",
       "      <td>actor</td>\n",
       "      <td>William K.L. Dickson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0240586</td>\n",
       "      <td>actor</td>\n",
       "      <td>William K.L. Dickson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst category           primaryName\n",
       "0  tt0177707    actor  William K.L. Dickson\n",
       "1  tt0240586    actor  William K.L. Dickson"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load actors_df\n",
    "try:\n",
    "    actors_df = pd.read_feather(\"data/actors.feather\")\n",
    "except:\n",
    "    try:\n",
    "        z = zipfile.ZipFile(get_path(\"data\\\\actors.zip\"))\n",
    "        actors_df = pd.read_feather(z.open(\"actors.feather\"))\n",
    "        actors.to_feather(\"data/actors.feather\")\n",
    "        try:\n",
    "            del z\n",
    "        except:\n",
    "            pass\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\n1: download from https://huggingface.co/datasets/Rykari/NetflixHackathon/resolve/main/actors.zip\\n2: place into data/ folder\")\n",
    "print(actors_df.shape)\n",
    "actors_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6130344, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>category</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>knownForTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>director</td>\n",
       "      <td>William K.L. Dickson</td>\n",
       "      <td>tt0219560,tt0308254,tt1428455,tt1496763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>director</td>\n",
       "      <td>William K.L. Dickson</td>\n",
       "      <td>tt0219560,tt0308254,tt1428455,tt1496763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst  category           primaryName  \\\n",
       "0  tt0000001  director  William K.L. Dickson   \n",
       "1  tt0000005  director  William K.L. Dickson   \n",
       "\n",
       "                            knownForTitles  \n",
       "0  tt0219560,tt0308254,tt1428455,tt1496763  \n",
       "1  tt0219560,tt0308254,tt1428455,tt1496763  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load directors_df\n",
    "try:\n",
    "    directors_df = pd.read_feather(\"data/directors.feather\")\n",
    "except:\n",
    "    try:\n",
    "        z = zipfile.ZipFile(get_path(\"data\\\\directors.zip\"))\n",
    "        directors_df = pd.read_feather(z.open(\"directors.feather\"))\n",
    "        directors_df.to_feather(\"data/directors.feather\")\n",
    "        try:\n",
    "            del z\n",
    "        except:\n",
    "            pass\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\n1: download from https://huggingface.co/datasets/Rykari/NetflixHackathon/resolve/main/directors.zip\\n2: place into data/ folder\")\n",
    "print(directors_df.shape)\n",
    "directors_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(879357, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>title</th>\n",
       "      <th>releaseYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>titleCleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>movie</td>\n",
       "      <td>miss jerry</td>\n",
       "      <td>1894</td>\n",
       "      <td>45</td>\n",
       "      <td>Romance</td>\n",
       "      <td>5.3</td>\n",
       "      <td>204</td>\n",
       "      <td>miss jerry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000147</td>\n",
       "      <td>movie</td>\n",
       "      <td>the corbett-fitzsimmons fight</td>\n",
       "      <td>1897</td>\n",
       "      <td>100</td>\n",
       "      <td>Documentary,News,Sport</td>\n",
       "      <td>5.3</td>\n",
       "      <td>465</td>\n",
       "      <td>the corbett fitzsimmons fight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst titleType                          title  releaseYear  \\\n",
       "0  tt0000009     movie                     miss jerry         1894   \n",
       "1  tt0000147     movie  the corbett-fitzsimmons fight         1897   \n",
       "\n",
       "   runtimeMinutes                  genres  imdbRating  numVotes  \\\n",
       "0              45                 Romance         5.3       204   \n",
       "1             100  Documentary,News,Sport         5.3       465   \n",
       "\n",
       "                    titleCleaned  \n",
       "0                     miss jerry  \n",
       "1  the corbett fitzsimmons fight  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load imdb_df\n",
    "try:\n",
    "    imdb_df = pd.read_feather(\"data/IMDB_CLEANED.feather\")\n",
    "except FileNotFoundError:\n",
    "    z = zipfile.ZipFile(get_path(\"data\\\\IMDB_CLEANED.zip\"))\n",
    "    imdb_df = pd.read_feather(z.open(\"IMDB_CLEANED.feather\"))\n",
    "    imdb_df.to_feather(\"data/IMDB_CLEANED.feather\")\n",
    "    try:\n",
    "        del z\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(imdb_df.shape)\n",
    "imdb_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5837, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>netflix_id</th>\n",
       "      <th>title</th>\n",
       "      <th>directors</th>\n",
       "      <th>cast</th>\n",
       "      <th>countries</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>releaseYear</th>\n",
       "      <th>maturityRating</th>\n",
       "      <th>duration</th>\n",
       "      <th>titleType</th>\n",
       "      <th>age_rating</th>\n",
       "      <th>suitability</th>\n",
       "      <th>genres</th>\n",
       "      <th>titleCleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81193313</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ha ji-won, yoon kye-sang, jang seung-jo, kang ...</td>\n",
       "      <td>south korea</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>16</td>\n",
       "      <td>Young Adults</td>\n",
       "      <td>International,Korean,Romance</td>\n",
       "      <td>chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81197050</td>\n",
       "      <td>guatemala: heart of the mayan world</td>\n",
       "      <td>luis ara, ignacio jaunsolo</td>\n",
       "      <td>christian morales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>67 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>0</td>\n",
       "      <td>Kids</td>\n",
       "      <td>Documentary,International</td>\n",
       "      <td>guatemala  heart of the mayan world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   netflix_id                                title  \\\n",
       "0    81193313                            chocolate   \n",
       "1    81197050  guatemala: heart of the mayan world   \n",
       "\n",
       "                    directors  \\\n",
       "0                         NaN   \n",
       "1  luis ara, ignacio jaunsolo   \n",
       "\n",
       "                                                cast    countries  dateAdded  \\\n",
       "0  ha ji-won, yoon kye-sang, jang seung-jo, kang ...  south korea 2019-11-30   \n",
       "1                                  christian morales          NaN 2019-11-30   \n",
       "\n",
       "   releaseYear maturityRating  duration titleType age_rating   suitability  \\\n",
       "0         2019          TV-14  1 Season  tvSeries         16  Young Adults   \n",
       "1         2019           TV-G    67 min     movie          0          Kids   \n",
       "\n",
       "                         genres                         titleCleaned  \n",
       "0  International,Korean,Romance                            chocolate  \n",
       "1     Documentary,International  guatemala  heart of the mayan world  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD NETFLIX DATA\n",
    "cleaned_df_with_IMDB = pd.read_pickle(get_path(\"data\\\\NETFLIX_CLEANED.pickle\"))\n",
    "print(cleaned_df_with_IMDB.shape)\n",
    "cleaned_df_with_IMDB.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5837, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>netflix_id</th>\n",
       "      <th>title</th>\n",
       "      <th>directors</th>\n",
       "      <th>cast</th>\n",
       "      <th>countries</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>releaseYear</th>\n",
       "      <th>maturityRating</th>\n",
       "      <th>duration</th>\n",
       "      <th>titleType</th>\n",
       "      <th>...</th>\n",
       "      <th>genres</th>\n",
       "      <th>titleCleaned</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>duplicateIds</th>\n",
       "      <th>numDuplicates</th>\n",
       "      <th>isMissing</th>\n",
       "      <th>ngramMatchedTitle</th>\n",
       "      <th>ngramConfidence</th>\n",
       "      <th>filteredOn</th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81193313</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ha ji-won, yoon kye-sang, jang seung-jo, kang ...</td>\n",
       "      <td>south korea</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>...</td>\n",
       "      <td>International,Korean,Romance</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81197050</td>\n",
       "      <td>guatemala: heart of the mayan world</td>\n",
       "      <td>luis ara, ignacio jaunsolo</td>\n",
       "      <td>christian morales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>67 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Documentary,International</td>\n",
       "      <td>guatemala  heart of the mayan world</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   netflix_id                                title  \\\n",
       "0    81193313                            chocolate   \n",
       "1    81197050  guatemala: heart of the mayan world   \n",
       "\n",
       "                    directors  \\\n",
       "0                         NaN   \n",
       "1  luis ara, ignacio jaunsolo   \n",
       "\n",
       "                                                cast    countries  dateAdded  \\\n",
       "0  ha ji-won, yoon kye-sang, jang seung-jo, kang ...  south korea 2019-11-30   \n",
       "1                                  christian morales          NaN 2019-11-30   \n",
       "\n",
       "   releaseYear maturityRating  duration titleType  ...  \\\n",
       "0         2019          TV-14  1 Season  tvSeries  ...   \n",
       "1         2019           TV-G    67 min     movie  ...   \n",
       "\n",
       "                         genres                         titleCleaned imdb_id  \\\n",
       "0  International,Korean,Romance                            chocolate     NaN   \n",
       "1     Documentary,International  guatemala  heart of the mayan world     NaN   \n",
       "\n",
       "  duplicateIds  numDuplicates  isMissing  ngramMatchedTitle  ngramConfidence  \\\n",
       "0          NaN              0      False                NaN              NaN   \n",
       "1          NaN              0      False                NaN              NaN   \n",
       "\n",
       "   filteredOn  errors  \n",
       "0         NaN     NaN  \n",
       "1         NaN     NaN  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function will add some additional columns so let's set them up:\n",
    "cleaned_df_with_IMDB[\"imdb_id\"] = np.NaN            # REQUIRED\n",
    "\n",
    "cleaned_df_with_IMDB[\"duplicateIds\"] = np.NaN       # STRING: FOR TITLES THAT COULD NOT BE FILTERED TO 1 EXACT MATCH\n",
    "cleaned_df_with_IMDB[\"numDuplicates\"] = np.int8(0)  # INT: HOW MANY OF THE SAME NAME FOUND\n",
    "\n",
    "cleaned_df_with_IMDB[\"isMissing\"] = np.int8(0)      # BOOL: FOR TITLES THAT COULD NOT BE FOUND AT ALL\n",
    "cleaned_df_with_IMDB[\"isMissing\"] = cleaned_df_with_IMDB[\"isMissing\"].astype(\"bool\")\n",
    "\n",
    "cleaned_df_with_IMDB[\"ngramMatchedTitle\"] = np.NaN  # STRING THAT THE NGRAM SUCCESSFULLY MATCHED AGAINST\n",
    "cleaned_df_with_IMDB[\"ngramConfidence\"] = np.NaN    # FLOAT: CONFIDENCE OF NGRAM\n",
    "cleaned_df_with_IMDB[\"filteredOn\"] = np.NaN         # STRING: WHICH STAGE DID WE FIND THE EXACT MATCH?\n",
    "cleaned_df_with_IMDB[\"errors\"] = np.NaN             # STRING: FOR DEBUGGING\n",
    "print(cleaned_df_with_IMDB.shape)\n",
    "cleaned_df_with_IMDB.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching netflix_id to imdb_id\n",
    "### This is a heavy function & a first attempt\n",
    "- Might need to remove all special characters from titles - possibly replace with a space?\n",
    "- How does FuzzyWuzzy perform? \n",
    "  - ANS: POORLY. 1 string can take anywhere from 25 seconds to 50 seconds to perform.\n",
    "- How do ngrams perform? \n",
    "  - Can compare 5837 strings against 879357 in ~25 to 30mins\n",
    "- Add multithreading / multiprocessing / .. something??\n",
    "  - I seriously lack the understanding to do this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will attempt ngrams if titles without an exact match...\n",
    "# So let's start with a ground truth ngram table\n",
    "G = ngram.NGram(imdb_df[\"titleCleaned\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39582253edfd416286d9102b8c64e691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 32min 36s\n",
      "Wall time: 32min 50s\n"
     ]
    }
   ],
   "source": [
    "def MatchNetflixToIMDB(DF_TO_PROCESS: pd.DataFrame, breakvar: int = 0):\n",
    "\n",
    "    # TODO: REVISIT Function & overall logic. .explode might be faster\n",
    "    def listOf_(dataframe: pd.DataFrame, column: str) -> list:\n",
    "        if dataframe[~dataframe[column].isna()].shape[0]:   # If dataframe is not empty\n",
    "            str_of_ = dataframe[column].values[0]           # Genres is a category dtype so need to convert to a str\n",
    "            if ', ' in str(str_of_):                        # If ', ' is in the string then there's more than 1 entry\n",
    "                return str_of_.split(\", \")\n",
    "            else:\n",
    "                return [str_of_]                        # Otherwise there's a single entry\n",
    "        else:\n",
    "            return []                                   # incase something else breaks above, nan/string encoding issue, etc\n",
    "\n",
    "    def isMatch(search_dataframe: pd.DataFrame) -> bool:\n",
    "        if search_dataframe.shape[0] == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def isMissing(search_dataframe: pd.DataFrame) -> bool:\n",
    "        if search_dataframe.shape[0] == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def add_imdbID_to_df(search_dataframe: pd.DataFrame):\n",
    "        DF_TO_PROCESS.loc[i, \"imdb_id\"] = search_dataframe[\"tconst\"].values[0]\n",
    "\n",
    "    def add_missing_to_df():\n",
    "        DF_TO_PROCESS.loc[i, \"isMissing\"] = True\n",
    "\n",
    "\n",
    "    def add_duplicates_to_df(search_dataframe: pd.DataFrame):\n",
    "        DF_TO_PROCESS.loc[i, \"numDuplicates\"] = int(search_dataframe.shape[0])\n",
    "        string_of_duplicates = search_dataframe.groupby(\"title\", as_index=False).agg({\"tconst\": lambda x: ', '.join(x)})[\"tconst\"].values[0]\n",
    "        DF_TO_PROCESS.loc[i, \"duplicateIds\"] = string_of_duplicates\n",
    "\n",
    "\n",
    "    def try_ngram_match():\n",
    "        title_name = current[\"titleCleaned\"].values[0]\n",
    "        try:\n",
    "            title, confidence = G.search(title_name)[0]\n",
    "            # title = G.find(title_name)[0] # Might be faster?\n",
    "            current.loc[i, \"ngramMatchedTitle\"] = title\n",
    "            current.loc[i, \"ngramConfidence\"] = confidence\n",
    "            del title\n",
    "            del confidence\n",
    "        except IndexError: # non alphanumeric strings like 'يوم الدين' will throw an error\n",
    "            current.loc[i, \"errors\"] = \"ngram error\"\n",
    "\n",
    "\n",
    "    def filterBy(columnName: str) -> pd.DataFrame:\n",
    "        \"\"\"Compare named column value of two dataframes. Will return the compared provided it:\n",
    "            - Has less reults\n",
    "            - Isn't empty\n",
    "\n",
    "            Otherwise it will return the original dataframe\n",
    "\n",
    "        Args:\n",
    "            columnName (str): Name of the column who's values you wish to compare\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered dataframe that isn't empty\n",
    "        \"\"\"\n",
    "\n",
    "        tmp = filter[filter[columnName] == current[columnName].values[0]]\n",
    "        if (tmp.shape[0] < filter.shape[0]) & (tmp.shape[0] != 0):\n",
    "            return tmp\n",
    "        else:\n",
    "            return filter\n",
    "\n",
    "    # break after 'breakvar' iterations - used for debugging\n",
    "    if not breakvar:\n",
    "        stop = DF_TO_PROCESS.shape[0]\n",
    "    else:\n",
    "        stop = breakvar\n",
    "\n",
    "    missing_count = 0\n",
    "    my_range = tqdm(range(0, stop)) # Check impact on performance\n",
    "    for i in my_range:\n",
    "        filtered = 0 # TODO: DEBUGGING VAR - Due to continue not working as intended - investigate\n",
    "        current = DF_TO_PROCESS.iloc[[i]].copy()\n",
    "        my_range.set_description(f\"Progress: \")\n",
    "        my_range.set_postfix({'Missing IMDB IDs': missing_count, \"Title: \": current[\"title\"].values[0]})\n",
    "\n",
    "        # 1: Try to find a direct title match\n",
    "        filter = imdb_df[imdb_df[\"titleCleaned\"] == current[\"titleCleaned\"].values[0]]\n",
    "\n",
    "        # If .shape[0] = 1, exact match found. Add ID & go to next iteration\n",
    "        if isMatch(filter):\n",
    "            add_imdbID_to_df(filter)\n",
    "            DF_TO_PROCESS.loc[i, \"filteredOn\"] = \"titleCleaned\"\n",
    "            filtered += 1\n",
    "            continue # PROCEED TO NEXT ITERATION\n",
    "\n",
    "        # If .shape[0] = 0, exact match NOT found. try ngram match\n",
    "        elif isMissing(filter):\n",
    "            try_ngram_match()\n",
    "\n",
    "            # If .shape[0] is 0, add to missing & continue to next iteration\n",
    "            if current[\"errors\"].values[0] == \"ngram error\": \n",
    "                filtered += 1\n",
    "                missing_count += 1\n",
    "                continue\n",
    "\n",
    "            # Otherwise try again to filter\n",
    "            else:\n",
    "                filter = imdb_df[imdb_df[\"titleCleaned\"] == current[\"ngramMatchedTitle\"].values[0]]\n",
    "\n",
    "                # If .shape[0] = 1, exact match is found. Add ID & go to next iteration\n",
    "                if isMatch(filter):\n",
    "                    add_imdbID_to_df(filter)\n",
    "                    DF_TO_PROCESS.loc[i, \"filteredOn\"] = \"ngramMatchedTitle\"\n",
    "                    filtered += 1\n",
    "                    continue\n",
    "\n",
    "\n",
    "        # IF CODE CONTINUES AFTER THIS POINT, ASSUME MULTIPLE ID'S FOUND (Titles with the same name)\n",
    "\n",
    "        # 3: Try to find a single match using titleType\n",
    "        if not filtered:\n",
    "            filter = filterBy(\"titleType\")\n",
    "            if isMatch(filter):\n",
    "                add_imdbID_to_df(filter)\n",
    "                DF_TO_PROCESS.loc[i, \"filteredOn\"] = \"titleType\"\n",
    "                filtered += 1\n",
    "                continue\n",
    "\n",
    "        # 4: Try to find a single match using releaseYear\n",
    "        if not filtered:\n",
    "            filter = filterBy(\"releaseYear\")\n",
    "            if isMatch(filter):\n",
    "                add_imdbID_to_df(filter)\n",
    "                DF_TO_PROCESS.loc[i, \"filteredOn\"] = \"releaseYear\"\n",
    "                filtered += 1\n",
    "                continue\n",
    "\n",
    "\n",
    "        # 5: Try to find a single match using director\n",
    "        if not filtered:\n",
    "            if current[\"directors\"].notna().values[0]:\n",
    "                lst_tconst = list(filter[\"tconst\"]) # list of remaining imdb_id's from the shortest list above\n",
    "                if (len(lst_tconst) > 0) & (filtered == 0):\n",
    "                    list_of_directors = listOf_(current, \"directors\")\n",
    "                    tmp_directors = directors_df[directors_df[\"tconst\"].isin(lst_tconst)] # Want to avoid .isin() - efficiency. Better way?\n",
    "                    lst_director = list(set(tmp_directors[\"primaryName\"]) & set(list_of_directors)) # Find matching names using set\n",
    "                    # TODO: Flawed logic. Many movies have multiple directors. Use method below\n",
    "                    if len(lst_director) == 1:\n",
    "                        tmp_tconst = tmp_directors[tmp_directors[\"primaryName\"]==lst_director[0]][\"tconst\"].values[0]\n",
    "                        DF_TO_PROCESS.loc[i, \"imdb_id\"] = tmp_tconst\n",
    "                        DF_TO_PROCESS.loc[i, \"filteredOn\"] = \"directors\"\n",
    "                        filtered +=1\n",
    "                        continue\n",
    "\n",
    "        # 6: Try to find a single match using actors\n",
    "        if not filtered:\n",
    "            if current[\"cast\"].notna().values[0]:\n",
    "                lst_tconst = list(filter[\"tconst\"]) # list of remaining imdb_id's\n",
    "                if (len(lst_tconst) > 0) & (filtered == 0):\n",
    "                    list_of_actors = listOf_(current, \"cast\")\n",
    "                    tmp_actors = actors_df[actors_df[\"tconst\"].isin(lst_tconst)] # Want to avoid .isin() - efficiency. Better way?\n",
    "                    lst_actor = list(set(tmp_actors[\"primaryName\"]) & set(list_of_actors)) # Get a union of matching actors between cleaned_df & tmp_actors\n",
    "                    dct_tconst = {}\n",
    "                    if lst_actor:\n",
    "                        for actor in lst_actor: # For each actor that matches\n",
    "                            try:                # create a key:value pair that counts each triggered occurence per id\n",
    "                                dct_tconst[tmp_actors[tmp_actors[\"primaryName\"] == actor][\"tconst\"].values[0]] += 1\n",
    "                            except KeyError:\n",
    "                                dct_tconst[tmp_actors[tmp_actors[\"primaryName\"] == actor][\"tconst\"].values[0]] = 1\n",
    "                        # TODO: Handle logic to account for rare case: multiple ID's with the same max() value\n",
    "                        DF_TO_PROCESS.loc[i, \"imdb_id\"] = max(dct_tconst.keys()) # The ID with the highest matching count gets added\n",
    "                        DF_TO_PROCESS.loc[i, \"filteredOn\"] = \"actors\"\n",
    "                        filtered +=1\n",
    "                        continue\n",
    "\n",
    "        # TODO: Improve logic. Continue not working as I expect? Fix it! Spamming \"& (not filtered)\" is a tedious pain in the ass & affects performance\n",
    "        # Added & (not filtered) in attempt to improve performance\n",
    "\n",
    "        # If none of the above filters worked, add the duplicate id's to dataframe, set missing to true & start next iteration\n",
    "        if (filter.shape[0] > 1) & (not filtered):\n",
    "            add_duplicates_to_df(filter)\n",
    "            missing_count += 1\n",
    "            continue\n",
    "\n",
    "        # DEBUG Function: This should never trigger. If it does then there's a flaw in the logic\n",
    "        if (filter.shape[0] == 0) & (not filtered):\n",
    "            add_missing_to_df()\n",
    "            missing_count += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "        # DEBUG Function: This should never trigger. If it does then there's a flaw in the logic\n",
    "        if not filtered:\n",
    "            DF_TO_PROCESS.loc[i, \"errors\"] = \"not found at all\"\n",
    "            missing_count += 1\n",
    "            continue\n",
    "\n",
    "# For testing:\n",
    "# number_of_times_to_iterate = 50\n",
    "# %time MatchNetflixToIMDB(cleaned_df_with_IMDB, number_of_times_to_iterate)\n",
    "\n",
    "%time MatchNetflixToIMDB(cleaned_df_with_IMDB)\n",
    "# Took 32 mins & 50s to run through 5837 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5837, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>netflix_id</th>\n",
       "      <th>title</th>\n",
       "      <th>directors</th>\n",
       "      <th>cast</th>\n",
       "      <th>countries</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>releaseYear</th>\n",
       "      <th>maturityRating</th>\n",
       "      <th>duration</th>\n",
       "      <th>titleType</th>\n",
       "      <th>...</th>\n",
       "      <th>genres</th>\n",
       "      <th>titleCleaned</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>duplicateIds</th>\n",
       "      <th>numDuplicates</th>\n",
       "      <th>isMissing</th>\n",
       "      <th>ngramMatchedTitle</th>\n",
       "      <th>ngramConfidence</th>\n",
       "      <th>filteredOn</th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81193313</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ha ji-won, yoon kye-sang, jang seung-jo, kang ...</td>\n",
       "      <td>south korea</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>...</td>\n",
       "      <td>International,Korean,Romance</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt11214028, tt12263402, tt18263132</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81197050</td>\n",
       "      <td>guatemala: heart of the mayan world</td>\n",
       "      <td>luis ara, ignacio jaunsolo</td>\n",
       "      <td>christian morales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>67 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Documentary,International</td>\n",
       "      <td>guatemala  heart of the mayan world</td>\n",
       "      <td>tt11505398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81213894</td>\n",
       "      <td>the zoya factor</td>\n",
       "      <td>abhishek sharma</td>\n",
       "      <td>sonam kapoor, dulquer salmaan, sanjay kapoor, ...</td>\n",
       "      <td>india</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>135 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Comedy,Drama,International</td>\n",
       "      <td>the zoya factor</td>\n",
       "      <td>tt8304386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81082007</td>\n",
       "      <td>atlantics</td>\n",
       "      <td>mati diop</td>\n",
       "      <td>mama sane, amadou mbow, ibrahima traore, nicol...</td>\n",
       "      <td>france, senegal, belgium</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>106 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Drama,Independent,International</td>\n",
       "      <td>atlantics</td>\n",
       "      <td>tt10199586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80213643</td>\n",
       "      <td>chip and potato</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abigail oliver, andrea libman, briana buckmast...</td>\n",
       "      <td>canada, united kingdom</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-Y</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>...</td>\n",
       "      <td>Family</td>\n",
       "      <td>chip and potato</td>\n",
       "      <td>tt9897038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81172754</td>\n",
       "      <td>crazy people</td>\n",
       "      <td>moses inwang</td>\n",
       "      <td>ramsey nouah, chigul, sola sobowale, ireti doy...</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2018</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>107 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Comedy,International,Thriller</td>\n",
       "      <td>crazy people</td>\n",
       "      <td>tt8542144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>releaseYear</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>81120982</td>\n",
       "      <td>i lost my body</td>\n",
       "      <td>jérémy clapin</td>\n",
       "      <td>hakim faris, victoire du bois, patrick d'assum...</td>\n",
       "      <td>france</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>81 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Drama,Independent,International</td>\n",
       "      <td>i lost my body</td>\n",
       "      <td>tt9806192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81227195</td>\n",
       "      <td>kalushi: the story of solomon mahlangu</td>\n",
       "      <td>mandla dube</td>\n",
       "      <td>thabo rametsi, thabo malema, welile nzuza, jaf...</td>\n",
       "      <td>south africa</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>107 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Drama,International</td>\n",
       "      <td>kalushi  the story of solomon mahlangu</td>\n",
       "      <td>tt3487278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70205672</td>\n",
       "      <td>la reina del sur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kate del castillo, cristina urgel, alberto jim...</td>\n",
       "      <td>united states, spain, colombia, mexico</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>...</td>\n",
       "      <td>Crime,International,Spanish</td>\n",
       "      <td>la reina del sur</td>\n",
       "      <td>tt1704637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>81172841</td>\n",
       "      <td>lagos real fake life</td>\n",
       "      <td>mike ezuruonye</td>\n",
       "      <td>nonso diobi, mike ezuruonye, mercy aigbe, rex ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2018</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>118 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Comedy,International</td>\n",
       "      <td>lagos real fake life</td>\n",
       "      <td>tt15150376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>81172899</td>\n",
       "      <td>payday</td>\n",
       "      <td>cheta chukwu</td>\n",
       "      <td>baaj adebule, ebiye victor, meg otanwa, bisola...</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2018</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>110 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Comedy,Independent,International</td>\n",
       "      <td>payday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt6250554, tt8960334</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>81094391</td>\n",
       "      <td>sugar rush christmas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hunter march, candace nelson, adriano zumbo</td>\n",
       "      <td>united states</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>...</td>\n",
       "      <td>Reality-TV</td>\n",
       "      <td>sugar rush christmas</td>\n",
       "      <td>tt11168116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>81172908</td>\n",
       "      <td>the accidental spy</td>\n",
       "      <td>roger russell</td>\n",
       "      <td>ramsey nouah, christine allado, ayo makun, emm...</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2017</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>104 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Comedy,International,Action,Adventure</td>\n",
       "      <td>the accidental spy</td>\n",
       "      <td>tt6921426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>releaseYear</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>81152641</td>\n",
       "      <td>the charming stepmom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shahkrit yamnarm, view wannarot sontichai, kri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>...</td>\n",
       "      <td>International,Romance,Comedy</td>\n",
       "      <td>the charming stepmom</td>\n",
       "      <td>tt13846404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>81172901</td>\n",
       "      <td>the island</td>\n",
       "      <td>toka mcbaror</td>\n",
       "      <td>sambasa nzeribe, segun arinze, tokunbo idowu, ...</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2018</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>93 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Drama,International,Thriller</td>\n",
       "      <td>the island</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt8755316, tt9125432, tt9823276</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>80990849</td>\n",
       "      <td>the movies that made us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>...</td>\n",
       "      <td>Docuseries</td>\n",
       "      <td>the movies that made us</td>\n",
       "      <td>tt10681222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleType</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>81033086</td>\n",
       "      <td>holiday rush</td>\n",
       "      <td>leslie small</td>\n",
       "      <td>romany malco, sonequa martin-green, darlene lo...</td>\n",
       "      <td>united states</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>94 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Family,Drama</td>\n",
       "      <td>holiday rush</td>\n",
       "      <td>tt10091530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80156799</td>\n",
       "      <td>levius</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nobunaga shimazaki, junichi suwabe, takahiro s...</td>\n",
       "      <td>japan</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>...</td>\n",
       "      <td>Animation,International</td>\n",
       "      <td>levius</td>\n",
       "      <td>tt10619444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>81161538</td>\n",
       "      <td>lugar de mulher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brazil</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>...</td>\n",
       "      <td>International,Comedy,Comedy,Talk-Show</td>\n",
       "      <td>lugar de mulher</td>\n",
       "      <td>tt11215186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>80997965</td>\n",
       "      <td>merry happy whatever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dennis quaid, bridgit mendler, brent morin, as...</td>\n",
       "      <td>united states</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>merry happy whatever</td>\n",
       "      <td>tt9770286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titleCleaned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    netflix_id                                   title  \\\n",
       "0     81193313                               chocolate   \n",
       "1     81197050     guatemala: heart of the mayan world   \n",
       "2     81213894                         the zoya factor   \n",
       "3     81082007                               atlantics   \n",
       "4     80213643                         chip and potato   \n",
       "5     81172754                            crazy people   \n",
       "6     81120982                          i lost my body   \n",
       "7     81227195  kalushi: the story of solomon mahlangu   \n",
       "8     70205672                        la reina del sur   \n",
       "9     81172841                    lagos real fake life   \n",
       "10    81172899                                  payday   \n",
       "11    81094391                    sugar rush christmas   \n",
       "12    81172908                      the accidental spy   \n",
       "13    81152641                    the charming stepmom   \n",
       "14    81172901                              the island   \n",
       "15    80990849                 the movies that made us   \n",
       "16    81033086                            holiday rush   \n",
       "17    80156799                                  levius   \n",
       "18    81161538                         lugar de mulher   \n",
       "19    80997965                    merry happy whatever   \n",
       "\n",
       "                     directors  \\\n",
       "0                          NaN   \n",
       "1   luis ara, ignacio jaunsolo   \n",
       "2              abhishek sharma   \n",
       "3                    mati diop   \n",
       "4                          NaN   \n",
       "5                 moses inwang   \n",
       "6                jérémy clapin   \n",
       "7                  mandla dube   \n",
       "8                          NaN   \n",
       "9               mike ezuruonye   \n",
       "10                cheta chukwu   \n",
       "11                         NaN   \n",
       "12               roger russell   \n",
       "13                         NaN   \n",
       "14                toka mcbaror   \n",
       "15                         NaN   \n",
       "16                leslie small   \n",
       "17                         NaN   \n",
       "18                         NaN   \n",
       "19                         NaN   \n",
       "\n",
       "                                                 cast  \\\n",
       "0   ha ji-won, yoon kye-sang, jang seung-jo, kang ...   \n",
       "1                                   christian morales   \n",
       "2   sonam kapoor, dulquer salmaan, sanjay kapoor, ...   \n",
       "3   mama sane, amadou mbow, ibrahima traore, nicol...   \n",
       "4   abigail oliver, andrea libman, briana buckmast...   \n",
       "5   ramsey nouah, chigul, sola sobowale, ireti doy...   \n",
       "6   hakim faris, victoire du bois, patrick d'assum...   \n",
       "7   thabo rametsi, thabo malema, welile nzuza, jaf...   \n",
       "8   kate del castillo, cristina urgel, alberto jim...   \n",
       "9   nonso diobi, mike ezuruonye, mercy aigbe, rex ...   \n",
       "10  baaj adebule, ebiye victor, meg otanwa, bisola...   \n",
       "11        hunter march, candace nelson, adriano zumbo   \n",
       "12  ramsey nouah, christine allado, ayo makun, emm...   \n",
       "13  shahkrit yamnarm, view wannarot sontichai, kri...   \n",
       "14  sambasa nzeribe, segun arinze, tokunbo idowu, ...   \n",
       "15                                                NaN   \n",
       "16  romany malco, sonequa martin-green, darlene lo...   \n",
       "17  nobunaga shimazaki, junichi suwabe, takahiro s...   \n",
       "18                                                NaN   \n",
       "19  dennis quaid, bridgit mendler, brent morin, as...   \n",
       "\n",
       "                                 countries  dateAdded  releaseYear  \\\n",
       "0                              south korea 2019-11-30         2019   \n",
       "1                                      NaN 2019-11-30         2019   \n",
       "2                                    india 2019-11-30         2019   \n",
       "3                 france, senegal, belgium 2019-11-29         2019   \n",
       "4                   canada, united kingdom        NaT         2019   \n",
       "5                                  nigeria 2019-11-29         2018   \n",
       "6                                   france 2019-11-29         2019   \n",
       "7                             south africa 2019-11-29         2016   \n",
       "8   united states, spain, colombia, mexico        NaT         2019   \n",
       "9                                      NaN 2019-11-29         2018   \n",
       "10                                 nigeria 2019-11-29         2018   \n",
       "11                           united states 2019-11-29         2019   \n",
       "12                                 nigeria 2019-11-29         2017   \n",
       "13                                     NaN 2019-11-29         2019   \n",
       "14                                 nigeria 2019-11-29         2018   \n",
       "15                           united states 2019-11-29         2019   \n",
       "16                           united states 2019-11-28         2019   \n",
       "17                                   japan 2019-11-28         2019   \n",
       "18                                  brazil 2019-11-28         2019   \n",
       "19                           united states 2019-11-28         2019   \n",
       "\n",
       "   maturityRating   duration titleType  ...  \\\n",
       "0           TV-14   1 Season  tvSeries  ...   \n",
       "1            TV-G     67 min     movie  ...   \n",
       "2           TV-14    135 min     movie  ...   \n",
       "3           TV-14    106 min     movie  ...   \n",
       "4            TV-Y  2 Seasons  tvSeries  ...   \n",
       "5           TV-14    107 min     movie  ...   \n",
       "6           TV-MA     81 min     movie  ...   \n",
       "7           TV-MA    107 min     movie  ...   \n",
       "8           TV-14  2 Seasons  tvSeries  ...   \n",
       "9           TV-14    118 min     movie  ...   \n",
       "10          TV-MA    110 min     movie  ...   \n",
       "11          TV-PG   1 Season  tvSeries  ...   \n",
       "12          TV-14    104 min     movie  ...   \n",
       "13          TV-14   1 Season  tvSeries  ...   \n",
       "14          TV-14     93 min     movie  ...   \n",
       "15          TV-MA   1 Season  tvSeries  ...   \n",
       "16          TV-PG     94 min     movie  ...   \n",
       "17          TV-14   1 Season  tvSeries  ...   \n",
       "18          TV-MA   1 Season  tvSeries  ...   \n",
       "19          TV-PG   1 Season  tvSeries  ...   \n",
       "\n",
       "                                   genres  \\\n",
       "0            International,Korean,Romance   \n",
       "1               Documentary,International   \n",
       "2              Comedy,Drama,International   \n",
       "3         Drama,Independent,International   \n",
       "4                                  Family   \n",
       "5           Comedy,International,Thriller   \n",
       "6         Drama,Independent,International   \n",
       "7                     Drama,International   \n",
       "8             Crime,International,Spanish   \n",
       "9                    Comedy,International   \n",
       "10       Comedy,Independent,International   \n",
       "11                             Reality-TV   \n",
       "12  Comedy,International,Action,Adventure   \n",
       "13           International,Romance,Comedy   \n",
       "14           Drama,International,Thriller   \n",
       "15                             Docuseries   \n",
       "16                           Family,Drama   \n",
       "17                Animation,International   \n",
       "18  International,Comedy,Comedy,Talk-Show   \n",
       "19                                 Comedy   \n",
       "\n",
       "                              titleCleaned     imdb_id  \\\n",
       "0                                chocolate         NaN   \n",
       "1      guatemala  heart of the mayan world  tt11505398   \n",
       "2                          the zoya factor   tt8304386   \n",
       "3                                atlantics  tt10199586   \n",
       "4                          chip and potato   tt9897038   \n",
       "5                             crazy people   tt8542144   \n",
       "6                           i lost my body   tt9806192   \n",
       "7   kalushi  the story of solomon mahlangu   tt3487278   \n",
       "8                         la reina del sur   tt1704637   \n",
       "9                     lagos real fake life  tt15150376   \n",
       "10                                  payday         NaN   \n",
       "11                    sugar rush christmas  tt11168116   \n",
       "12                      the accidental spy   tt6921426   \n",
       "13                    the charming stepmom  tt13846404   \n",
       "14                              the island         NaN   \n",
       "15                 the movies that made us  tt10681222   \n",
       "16                            holiday rush  tt10091530   \n",
       "17                                  levius  tt10619444   \n",
       "18                         lugar de mulher  tt11215186   \n",
       "19                    merry happy whatever   tt9770286   \n",
       "\n",
       "                          duplicateIds numDuplicates isMissing  \\\n",
       "0   tt11214028, tt12263402, tt18263132             3     False   \n",
       "1                                  NaN             0     False   \n",
       "2                                  NaN             0     False   \n",
       "3                                  NaN             0     False   \n",
       "4                                  NaN             0     False   \n",
       "5                                  NaN             0     False   \n",
       "6                                  NaN             0     False   \n",
       "7                                  NaN             0     False   \n",
       "8                                  NaN             0     False   \n",
       "9                                  NaN             0     False   \n",
       "10                tt6250554, tt8960334             2     False   \n",
       "11                                 NaN             0     False   \n",
       "12                                 NaN             0     False   \n",
       "13                                 NaN             0     False   \n",
       "14     tt8755316, tt9125432, tt9823276             3     False   \n",
       "15                                 NaN             0     False   \n",
       "16                                 NaN             0     False   \n",
       "17                                 NaN             0     False   \n",
       "18                                 NaN             0     False   \n",
       "19                                 NaN             0     False   \n",
       "\n",
       "    ngramMatchedTitle  ngramConfidence    filteredOn  errors  \n",
       "0                 NaN              NaN           NaN     NaN  \n",
       "1                 NaN              NaN  titleCleaned     NaN  \n",
       "2                 NaN              NaN  titleCleaned     NaN  \n",
       "3                 NaN              NaN  titleCleaned     NaN  \n",
       "4                 NaN              NaN  titleCleaned     NaN  \n",
       "5                 NaN              NaN   releaseYear     NaN  \n",
       "6                 NaN              NaN  titleCleaned     NaN  \n",
       "7                 NaN              NaN  titleCleaned     NaN  \n",
       "8                 NaN              NaN  titleCleaned     NaN  \n",
       "9                 NaN              NaN  titleCleaned     NaN  \n",
       "10                NaN              NaN           NaN     NaN  \n",
       "11                NaN              NaN  titleCleaned     NaN  \n",
       "12                NaN              NaN   releaseYear     NaN  \n",
       "13                NaN              NaN  titleCleaned     NaN  \n",
       "14                NaN              NaN           NaN     NaN  \n",
       "15                NaN              NaN     titleType     NaN  \n",
       "16                NaN              NaN  titleCleaned     NaN  \n",
       "17                NaN              NaN  titleCleaned     NaN  \n",
       "18                NaN              NaN  titleCleaned     NaN  \n",
       "19                NaN              NaN  titleCleaned     NaN  \n",
       "\n",
       "[20 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cleaned_df_with_IMDB.shape)\n",
    "cleaned_df_with_IMDB.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full thing to csv:\n",
    "cleaned_df_with_IMDB.to_csv(\"data/cleaned_df_with_IMDB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>netflix_id</th>\n",
       "      <th>title</th>\n",
       "      <th>directors</th>\n",
       "      <th>cast</th>\n",
       "      <th>countries</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>releaseYear</th>\n",
       "      <th>maturityRating</th>\n",
       "      <th>duration</th>\n",
       "      <th>titleType</th>\n",
       "      <th>...</th>\n",
       "      <th>genres</th>\n",
       "      <th>titleCleaned</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>duplicateIds</th>\n",
       "      <th>numDuplicates</th>\n",
       "      <th>isMissing</th>\n",
       "      <th>ngramMatchedTitle</th>\n",
       "      <th>ngramConfidence</th>\n",
       "      <th>filteredOn</th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81193313</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ha ji-won, yoon kye-sang, jang seung-jo, kang ...</td>\n",
       "      <td>south korea</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>...</td>\n",
       "      <td>International,Korean,Romance</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt11214028, tt12263402, tt18263132</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>81172899</td>\n",
       "      <td>payday</td>\n",
       "      <td>cheta chukwu</td>\n",
       "      <td>baaj adebule, ebiye victor, meg otanwa, bisola...</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2018</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>110 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Comedy,Independent,International</td>\n",
       "      <td>payday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt6250554, tt8960334</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    netflix_id      title     directors  \\\n",
       "0     81193313  chocolate           NaN   \n",
       "10    81172899     payday  cheta chukwu   \n",
       "\n",
       "                                                 cast    countries  dateAdded  \\\n",
       "0   ha ji-won, yoon kye-sang, jang seung-jo, kang ...  south korea 2019-11-30   \n",
       "10  baaj adebule, ebiye victor, meg otanwa, bisola...      nigeria 2019-11-29   \n",
       "\n",
       "    releaseYear maturityRating  duration titleType  ...  \\\n",
       "0          2019          TV-14  1 Season  tvSeries  ...   \n",
       "10         2018          TV-MA   110 min     movie  ...   \n",
       "\n",
       "                              genres titleCleaned imdb_id  \\\n",
       "0       International,Korean,Romance    chocolate     NaN   \n",
       "10  Comedy,Independent,International       payday     NaN   \n",
       "\n",
       "                          duplicateIds numDuplicates isMissing  \\\n",
       "0   tt11214028, tt12263402, tt18263132             3     False   \n",
       "10                tt6250554, tt8960334             2     False   \n",
       "\n",
       "    ngramMatchedTitle  ngramConfidence  filteredOn  errors  \n",
       "0                 NaN              NaN         NaN     NaN  \n",
       "10                NaN              NaN         NaN     NaN  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_ids = cleaned_df_with_IMDB[cleaned_df_with_IMDB[\"imdb_id\"].isna()]\n",
    "print(missing_ids.shape)\n",
    "missing_ids.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unfortunately some of the titleTypes are mislabled too.... GHAAAD\n",
    "# # Will use this later once efficiency is improved on previous function\n",
    "\n",
    "\n",
    "# imdb_df_2 = pd.read_feather(\"data/imdb_df_full.feather\")\n",
    "# imdb_df_2.rename(columns={\"startYear\": \"releaseYear\", \"primaryTitle\": \"title\", \"averageRating\": \"imdbRating\"}, inplace=True)\n",
    "# imdb_df_2[\"titleCleaned\"] = imdb_df_2[[\"title\"]].applymap(tocleanstring)\n",
    "# imdb_df_2 = imdb_df_2[\n",
    "#     (imdb_df_2[\"titleType\"] == \"short\") |\n",
    "#     (imdb_df_2[\"titleType\"] == \"tvShort\") |\n",
    "#     (imdb_df_2[\"titleType\"] == \"tvMovie\") |\n",
    "#     (imdb_df_2[\"titleType\"] == \"tvMiniSeries\") |\n",
    "#     (imdb_df_2[\"titleType\"] == \"tvSpecial\") |\n",
    "#     (imdb_df_2[\"titleType\"] == \"video\") |\n",
    "#     (imdb_df_2[\"titleType\"] == \"tvPilot\")\n",
    "#     ].copy()\n",
    "# imdb_df_2.replace('\\\\N', np.NaN, inplace=True)\n",
    "# imdb_df_2.reset_index(drop=True, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34d53fb98219b7aa297780c5531bf6cf37a7200fceb7198a7dbad2919af90897"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
