{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix dataset without user data\n",
    "During a previous hackathon, we were given a csv containing netflix data. I only had an hour and a half to produce some code. I decided to see what I could do given more time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ngram\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH HANDLING:\n",
    "def get_path(relative_path: str) -> str:\n",
    "    try:\n",
    "        basedir = os.path.dirname(os.path.abspath(__file__)) + \"\\\\\"\n",
    "    except NameError:\n",
    "        basedir = os.getcwd() + \"\\\\\"\n",
    "    return os.path.join(basedir, relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20840047, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>category</th>\n",
       "      <th>primaryName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0177707</td>\n",
       "      <td>actor</td>\n",
       "      <td>William K.L. Dickson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0240586</td>\n",
       "      <td>actor</td>\n",
       "      <td>William K.L. Dickson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst category           primaryName\n",
       "0  tt0177707    actor  William K.L. Dickson\n",
       "1  tt0240586    actor  William K.L. Dickson"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load actors_df\n",
    "try:\n",
    "    actors_df = pd.read_feather(\"data/actors.feather\")\n",
    "except:\n",
    "    try:\n",
    "        z = zipfile.ZipFile(get_path(\"data\\\\actors.zip\"))\n",
    "        actors_df = pd.read_feather(z.open(\"actors.feather\"))\n",
    "        actors.to_feather(\"data/actors.feather\")\n",
    "        try:\n",
    "            del z\n",
    "        except:\n",
    "            pass\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\n1: download from https://huggingface.co/datasets/Rykari/NetflixHackathon/resolve/main/actors.zip\\n2: place into data/ folder\")\n",
    "print(actors_df.shape)\n",
    "actors_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6130344, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>category</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>knownForTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>director</td>\n",
       "      <td>William K.L. Dickson</td>\n",
       "      <td>tt0219560,tt0308254,tt1428455,tt1496763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>director</td>\n",
       "      <td>William K.L. Dickson</td>\n",
       "      <td>tt0219560,tt0308254,tt1428455,tt1496763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst  category           primaryName  \\\n",
       "0  tt0000001  director  William K.L. Dickson   \n",
       "1  tt0000005  director  William K.L. Dickson   \n",
       "\n",
       "                            knownForTitles  \n",
       "0  tt0219560,tt0308254,tt1428455,tt1496763  \n",
       "1  tt0219560,tt0308254,tt1428455,tt1496763  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load directors_df\n",
    "try:\n",
    "    directors_df = pd.read_feather(\"data/directors.feather\")\n",
    "except:\n",
    "    try:\n",
    "        z = zipfile.ZipFile(get_path(\"data\\\\directors.zip\"))\n",
    "        directors_df = pd.read_feather(z.open(\"directors.feather\"))\n",
    "        directors_df.to_feather(\"data/directors.feather\")\n",
    "        try:\n",
    "            del z\n",
    "        except:\n",
    "            pass\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\n1: download from https://huggingface.co/datasets/Rykari/NetflixHackathon/resolve/main/directors.zip\\n2: place into data/ folder\")\n",
    "print(directors_df.shape)\n",
    "directors_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(879357, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>title</th>\n",
       "      <th>releaseYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>titleCleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>movie</td>\n",
       "      <td>miss jerry</td>\n",
       "      <td>1894</td>\n",
       "      <td>45</td>\n",
       "      <td>Romance</td>\n",
       "      <td>5.3</td>\n",
       "      <td>204</td>\n",
       "      <td>miss jerry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000147</td>\n",
       "      <td>movie</td>\n",
       "      <td>the corbett-fitzsimmons fight</td>\n",
       "      <td>1897</td>\n",
       "      <td>100</td>\n",
       "      <td>Documentary,News,Sport</td>\n",
       "      <td>5.3</td>\n",
       "      <td>465</td>\n",
       "      <td>the corbett fitzsimmons fight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst titleType                          title  releaseYear  \\\n",
       "0  tt0000009     movie                     miss jerry         1894   \n",
       "1  tt0000147     movie  the corbett-fitzsimmons fight         1897   \n",
       "\n",
       "   runtimeMinutes                  genres  imdbRating  numVotes  \\\n",
       "0              45                 Romance         5.3       204   \n",
       "1             100  Documentary,News,Sport         5.3       465   \n",
       "\n",
       "                    titleCleaned  \n",
       "0                     miss jerry  \n",
       "1  the corbett fitzsimmons fight  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load imdb_df\n",
    "try:\n",
    "    imdb_df = pd.read_feather(\"data/IMDB_CLEANED.feather\")\n",
    "except FileNotFoundError:\n",
    "    z = zipfile.ZipFile(get_path(\"data\\\\IMDB_CLEANED.zip\"))\n",
    "    imdb_df = pd.read_feather(z.open(\"IMDB_CLEANED.feather\"))\n",
    "    imdb_df.to_feather(\"data/IMDB_CLEANED.feather\")\n",
    "    try:\n",
    "        del z\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(imdb_df.shape)\n",
    "imdb_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5837, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>netflix_id</th>\n",
       "      <th>title</th>\n",
       "      <th>directors</th>\n",
       "      <th>cast</th>\n",
       "      <th>countries</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>releaseYear</th>\n",
       "      <th>maturityRating</th>\n",
       "      <th>duration</th>\n",
       "      <th>titleType</th>\n",
       "      <th>age_rating</th>\n",
       "      <th>suitability</th>\n",
       "      <th>genres</th>\n",
       "      <th>titleCleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81193313</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ha ji-won, yoon kye-sang, jang seung-jo, kang ...</td>\n",
       "      <td>south korea</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>16</td>\n",
       "      <td>Young Adults</td>\n",
       "      <td>International,Korean,Romance</td>\n",
       "      <td>chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81197050</td>\n",
       "      <td>guatemala: heart of the mayan world</td>\n",
       "      <td>luis ara, ignacio jaunsolo</td>\n",
       "      <td>christian morales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>67 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>0</td>\n",
       "      <td>Kids</td>\n",
       "      <td>Documentary,International</td>\n",
       "      <td>guatemala  heart of the mayan world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   netflix_id                                title  \\\n",
       "0    81193313                            chocolate   \n",
       "1    81197050  guatemala: heart of the mayan world   \n",
       "\n",
       "                    directors  \\\n",
       "0                         NaN   \n",
       "1  luis ara, ignacio jaunsolo   \n",
       "\n",
       "                                                cast    countries  dateAdded  \\\n",
       "0  ha ji-won, yoon kye-sang, jang seung-jo, kang ...  south korea 2019-11-30   \n",
       "1                                  christian morales          NaN 2019-11-30   \n",
       "\n",
       "   releaseYear maturityRating  duration titleType age_rating   suitability  \\\n",
       "0         2019          TV-14  1 Season  tvSeries         16  Young Adults   \n",
       "1         2019           TV-G    67 min     movie          0          Kids   \n",
       "\n",
       "                         genres                         titleCleaned  \n",
       "0  International,Korean,Romance                            chocolate  \n",
       "1     Documentary,International  guatemala  heart of the mayan world  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD NETFLIX DATA\n",
    "cleaned_df_with_IMDB = pd.read_pickle(get_path(\"data\\\\NETFLIX_CLEANED.pickle\"))\n",
    "print(cleaned_df_with_IMDB.shape)\n",
    "cleaned_df_with_IMDB.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5837, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>netflix_id</th>\n",
       "      <th>title</th>\n",
       "      <th>directors</th>\n",
       "      <th>cast</th>\n",
       "      <th>countries</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>releaseYear</th>\n",
       "      <th>maturityRating</th>\n",
       "      <th>duration</th>\n",
       "      <th>titleType</th>\n",
       "      <th>...</th>\n",
       "      <th>genres</th>\n",
       "      <th>titleCleaned</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>duplicateIds</th>\n",
       "      <th>numDuplicates</th>\n",
       "      <th>isMissing</th>\n",
       "      <th>ngramMatchedTitle</th>\n",
       "      <th>ngramConfidence</th>\n",
       "      <th>filteredOn</th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81193313</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ha ji-won, yoon kye-sang, jang seung-jo, kang ...</td>\n",
       "      <td>south korea</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>...</td>\n",
       "      <td>International,Korean,Romance</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81197050</td>\n",
       "      <td>guatemala: heart of the mayan world</td>\n",
       "      <td>luis ara, ignacio jaunsolo</td>\n",
       "      <td>christian morales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>67 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>...</td>\n",
       "      <td>Documentary,International</td>\n",
       "      <td>guatemala  heart of the mayan world</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   netflix_id                                title  \\\n",
       "0    81193313                            chocolate   \n",
       "1    81197050  guatemala: heart of the mayan world   \n",
       "\n",
       "                    directors  \\\n",
       "0                         NaN   \n",
       "1  luis ara, ignacio jaunsolo   \n",
       "\n",
       "                                                cast    countries  dateAdded  \\\n",
       "0  ha ji-won, yoon kye-sang, jang seung-jo, kang ...  south korea 2019-11-30   \n",
       "1                                  christian morales          NaN 2019-11-30   \n",
       "\n",
       "   releaseYear maturityRating  duration titleType  ...  \\\n",
       "0         2019          TV-14  1 Season  tvSeries  ...   \n",
       "1         2019           TV-G    67 min     movie  ...   \n",
       "\n",
       "                         genres                         titleCleaned imdb_id  \\\n",
       "0  International,Korean,Romance                            chocolate     NaN   \n",
       "1     Documentary,International  guatemala  heart of the mayan world     NaN   \n",
       "\n",
       "  duplicateIds  numDuplicates  isMissing  ngramMatchedTitle  ngramConfidence  \\\n",
       "0          NaN              0      False                NaN              NaN   \n",
       "1          NaN              0      False                NaN              NaN   \n",
       "\n",
       "   filteredOn  errors  \n",
       "0         NaN     NaN  \n",
       "1         NaN     NaN  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function will add some additional columns so let's set them up:\n",
    "cleaned_df_with_IMDB[\"imdb_id\"] = np.NaN            # REQUIRED\n",
    "\n",
    "cleaned_df_with_IMDB[\"duplicateIds\"] = np.NaN       # STRING: FOR TITLES THAT COULD NOT BE FILTERED TO 1 EXACT MATCH\n",
    "cleaned_df_with_IMDB[\"numDuplicates\"] = np.int8(0)  # INT: HOW MANY OF THE SAME NAME FOUND\n",
    "\n",
    "cleaned_df_with_IMDB[\"isMissing\"] = np.int8(0)      # BOOL: FOR TITLES THAT COULD NOT BE FOUND AT ALL\n",
    "cleaned_df_with_IMDB[\"isMissing\"] = cleaned_df_with_IMDB[\"isMissing\"].astype(\"bool\")\n",
    "\n",
    "cleaned_df_with_IMDB[\"ngramMatchedTitle\"] = np.NaN  # STRING THAT THE NGRAM SUCCESSFULLY MATCHED AGAINST\n",
    "cleaned_df_with_IMDB[\"ngramConfidence\"] = np.NaN    # FLOAT: CONFIDENCE OF NGRAM\n",
    "cleaned_df_with_IMDB[\"filteredOn\"] = np.NaN         # STRING: WHICH STAGE DID WE FIND THE EXACT MATCH?\n",
    "cleaned_df_with_IMDB[\"errors\"] = np.NaN             # STRING: FOR DEBUGGING\n",
    "print(cleaned_df_with_IMDB.shape)\n",
    "cleaned_df_with_IMDB.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching netflix_id to imdb_id\n",
    "### This is a heavy function & a first attempt\n",
    "- Might need to remove all special characters from titles - possibly replace with a space?\n",
    "- How does FuzzyWuzzy perform? \n",
    "  - ANS: POORLY. 1 string can take anywhere from 25 seconds to 50 seconds to perform.\n",
    "- How do ngrams perform? \n",
    "  - Can compare 5837 strings against 879357 in ~25 to 30mins\n",
    "- Add multithreading / multiprocessing / .. something??\n",
    "  - I seriously lack the understanding to do this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will attempt ngrams if titles without an exact match...\n",
    "# So let's start with a ground truth ngram table\n",
    "G = ngram.NGram(imdb_df[\"titleCleaned\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39582253edfd416286d9102b8c64e691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def MatchNetflixToIMDB(DF_TO_PROCESS: pd.DataFrame, breakvar: int = 0):\n",
    "\n",
    "    # TODO: REVISIT Function & overall logic. .explode might be faster\n",
    "    def listOf_(dataframe: pd.DataFrame, column: str) -> list:\n",
    "        if dataframe[~dataframe[column].isna()].shape[0]:   # If dataframe is not empty\n",
    "            str_of_ = dataframe[column].values[0]           # Genres is a category dtype so need to convert to a str\n",
    "            if ', ' in str(str_of_):                        # If ', ' is in the string then there's more than 1 entry\n",
    "                return str_of_.split(\", \")\n",
    "            else:\n",
    "                return [str_of_]                        # Otherwise there's a single entry\n",
    "        else:\n",
    "            return []                                   # incase something else breaks above, nan/string encoding issue, etc\n",
    "\n",
    "    def isMatch(search_dataframe: pd.DataFrame) -> bool:\n",
    "        if search_dataframe.shape[0] == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def isMissing(search_dataframe: pd.DataFrame) -> bool:\n",
    "        if search_dataframe.shape[0] == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def add_imdbID_to_df(search_dataframe: pd.DataFrame):\n",
    "        DF_TO_PROCESS.loc[i, \"imdb_id\"] = search_dataframe[\"tconst\"].values[0]\n",
    "\n",
    "    def add_missing_to_df():\n",
    "        DF_TO_PROCESS.loc[i, \"isMissing\"] = True\n",
    "\n",
    "\n",
    "    def add_duplicates_to_df(search_dataframe: pd.DataFrame):\n",
    "        DF_TO_PROCESS.loc[i, \"numDuplicates\"] = int(search_dataframe.shape[0])\n",
    "        string_of_duplicates = search_dataframe.groupby(\"title\", as_index=False).agg({\"tconst\": lambda x: ', '.join(x)})[\"tconst\"].values[0]\n",
    "        DF_TO_PROCESS.loc[i, \"duplicateIds\"] = string_of_duplicates\n",
    "\n",
    "\n",
    "    def try_ngram_match():\n",
    "        title_name = current[\"titleCleaned\"].values[0]\n",
    "        try:\n",
    "            title, confidence = G.search(title_name)[0]\n",
    "            # title = G.find(title_name)[0] # Might be faster?\n",
    "            current.loc[i, \"ngramMatchedTitle\"] = title\n",
    "            current.loc[i, \"ngramConfidence\"] = confidence\n",
    "            del title\n",
    "            del confidence\n",
    "        except IndexError: # non alphanumeric strings like 'يوم الدين' will throw an error\n",
    "            current.loc[i, \"errors\"] = \"ngram error\"\n",
    "\n",
    "\n",
    "    def filterBy(columnName: str) -> pd.DataFrame:\n",
    "        \"\"\"Compare named column value of two dataframes. Will return the compared provided it:\n",
    "            - Has less reults\n",
    "            - Isn't empty\n",
    "\n",
    "            Otherwise it will return the original dataframe\n",
    "\n",
    "        Args:\n",
    "            columnName (str): Name of the column who's values you wish to compare\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered dataframe that isn't empty\n",
    "        \"\"\"\n",
    "\n",
    "        tmp = filter[filter[columnName] == current[columnName].values[0]]\n",
    "        if (tmp.shape[0] < filter.shape[0]) & (tmp.shape[0] != 0):\n",
    "            return tmp\n",
    "        else:\n",
    "            return filter\n",
    "\n",
    "    # break after 'breakvar' iterations - used for debugging\n",
    "    if not breakvar:\n",
    "        stop = DF_TO_PROCESS.shape[0]\n",
    "    else:\n",
    "        stop = breakvar\n",
    "\n",
    "    missing_count = 0\n",
    "    my_range = tqdm(range(0, stop)) # Check impact on performance\n",
    "    for i in my_range:\n",
    "        filtered = 0 # TODO: DEBUGGING VAR - Due to continue not working as intended - investigate\n",
    "        current = DF_TO_PROCESS.iloc[[i]].copy()\n",
    "        my_range.set_description(f\"Progress: \")\n",
    "        my_range.set_postfix({'Missing IMDB IDs': missing_count, \"Title: \": current[\"title\"].values[0]})\n",
    "\n",
    "        # 1: Try to find a direct title match\n",
    "        filter = imdb_df[imdb_df[\"titleCleaned\"] == current[\"titleCleaned\"].values[0]]\n",
    "\n",
    "        # If .shape[0] = 1, exact match found. Add ID & go to next iteration\n",
    "        if isMatch(filter):\n",
    "            add_imdbID_to_df(filter)\n",
    "            DF_TO_PROCESS.loc[i, \"filteredOn\"] = \"titleCleaned\"\n",
    "            filtered += 1\n",
    "            continue # PROCEED TO NEXT ITERATION\n",
    "\n",
    "        # If .shape[0] = 0, exact match NOT found. try ngram match\n",
    "        elif isMissing(filter):\n",
    "            try_ngram_match()\n",
    "\n",
    "            # If .shape[0] is 0, add to missing & continue to next iteration\n",
    "            if current[\"errors\"].values[0] == \"ngram error\": \n",
    "                filtered += 1\n",
    "                missing_count += 1\n",
    "                continue\n",
    "\n",
    "            # Otherwise try again to filter\n",
    "            else:\n",
    "                filter = imdb_df[imdb_df[\"titleCleaned\"] == current[\"ngramMatchedTitle\"].values[0]]\n",
    "\n",
    "                # If .shape[0] = 1, exact match is found. Add ID & go to next iteration\n",
    "                if isMatch(filter):\n",
    "                    add_imdbID_to_df(filter)\n",
    "                    DF_TO_PROCESS.loc[i, \"filteredOn\"] = \"ngramMatchedTitle\"\n",
    "                    filtered += 1\n",
    "                    continue\n",
    "\n",
    "\n",
    "        # IF CODE CONTINUES AFTER THIS POINT, ASSUME MULTIPLE ID'S FOUND (Titles with the same name)\n",
    "\n",
    "        # 3: Try to find a single match using titleType\n",
    "        if not filtered:\n",
    "            filter = filterBy(\"titleType\")\n",
    "            if isMatch(filter):\n",
    "                add_imdbID_to_df(filter)\n",
    "                DF_TO_PROCESS.loc[i, \"filteredOn\"] = \"titleType\"\n",
    "                filtered += 1\n",
    "                continue\n",
    "\n",
    "        # 4: Try to find a single match using releaseYear\n",
    "        if not filtered:\n",
    "            filter = filterBy(\"releaseYear\")\n",
    "            if isMatch(filter):\n",
    "                add_imdbID_to_df(filter)\n",
    "                DF_TO_PROCESS.loc[i, \"filteredOn\"] = \"releaseYear\"\n",
    "                filtered += 1\n",
    "                continue\n",
    "\n",
    "\n",
    "        # 5: Try to find a single match using director\n",
    "        if not filtered:\n",
    "            if current[\"directors\"].notna().values[0]:\n",
    "                lst_tconst = list(filter[\"tconst\"]) # list of remaining imdb_id's from the shortest list above\n",
    "                if (len(lst_tconst) > 0) & (filtered == 0):\n",
    "                    list_of_directors = listOf_(current, \"directors\")\n",
    "                    tmp_directors = directors_df[directors_df[\"tconst\"].isin(lst_tconst)] # Want to avoid .isin() - efficiency. Better way?\n",
    "                    lst_director = list(set(tmp_directors[\"primaryName\"]) & set(list_of_directors)) # Find matching names using set\n",
    "                    # TODO: Flawed logic. Many movies have multiple directors. Use method below\n",
    "                    if len(lst_director) == 1:\n",
    "                        tmp_tconst = tmp_directors[tmp_directors[\"primaryName\"]==lst_director[0]][\"tconst\"].values[0]\n",
    "                        DF_TO_PROCESS.loc[i, \"imdb_id\"] = tmp_tconst\n",
    "                        DF_TO_PROCESS.loc[i, \"filteredOn\"] = \"directors\"\n",
    "                        filtered +=1\n",
    "                        continue\n",
    "\n",
    "        # 6: Try to find a single match using actors\n",
    "        if not filtered:\n",
    "            if current[\"cast\"].notna().values[0]:\n",
    "                lst_tconst = list(filter[\"tconst\"]) # list of remaining imdb_id's\n",
    "                if (len(lst_tconst) > 0) & (filtered == 0):\n",
    "                    list_of_actors = listOf_(current, \"cast\")\n",
    "                    tmp_actors = actors_df[actors_df[\"tconst\"].isin(lst_tconst)] # Want to avoid .isin() - efficiency. Better way?\n",
    "                    lst_actor = list(set(tmp_actors[\"primaryName\"]) & set(list_of_actors)) # Get a union of matching actors between cleaned_df & tmp_actors\n",
    "                    dct_tconst = {}\n",
    "                    if lst_actor:\n",
    "                        for actor in lst_actor: # For each actor that matches\n",
    "                            try:                # create a key:value pair that counts each triggered occurence per id\n",
    "                                dct_tconst[tmp_actors[tmp_actors[\"primaryName\"] == actor][\"tconst\"].values[0]] += 1\n",
    "                            except KeyError:\n",
    "                                dct_tconst[tmp_actors[tmp_actors[\"primaryName\"] == actor][\"tconst\"].values[0]] = 1\n",
    "                        # TODO: Handle logic to account for rare case: multiple ID's with the same max() value\n",
    "                        DF_TO_PROCESS.loc[i, \"imdb_id\"] = max(dct_tconst.keys()) # The ID with the highest matching count gets added\n",
    "                        DF_TO_PROCESS.loc[i, \"filteredOn\"] = \"actors\"\n",
    "                        filtered +=1\n",
    "                        continue\n",
    "\n",
    "        # TODO: Improve logic. Continue not working as I expect? Fix it! Spamming \"& (not filtered)\" is a tedious pain in the ass & affects performance\n",
    "        # Added & (not filtered) in attempt to improve performance\n",
    "\n",
    "        # If none of the above filters worked, add the duplicate id's to dataframe, set missing to true & start next iteration\n",
    "        if (filter.shape[0] > 1) & (not filtered):\n",
    "            add_duplicates_to_df(filter)\n",
    "            missing_count += 1\n",
    "            continue\n",
    "\n",
    "        # DEBUG Function: This should never trigger. If it does then there's a flaw in the logic\n",
    "        if (filter.shape[0] == 0) & (not filtered):\n",
    "            add_missing_to_df()\n",
    "            missing_count += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "        # DEBUG Function: This should never trigger. If it does then there's a flaw in the logic\n",
    "        if not filtered:\n",
    "            DF_TO_PROCESS.loc[i, \"errors\"] = \"not found at all\"\n",
    "            missing_count += 1\n",
    "            continue\n",
    "\n",
    "# For testing:\n",
    "# number_of_times_to_iterate = 50\n",
    "# %time MatchNetflixToIMDB(cleaned_df_with_IMDB, number_of_times_to_iterate)\n",
    "\n",
    "%time MatchNetflixToIMDB(cleaned_df_with_IMDB)\n",
    "# Took ~30mins to run through 5837 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_df_with_IMDB.shape)\n",
    "cleaned_df_with_IMDB.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full thing to csv:\n",
    "cleaned_df_with_IMDB.to_csv(\"data/cleaned_df_with_IMDB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ids = cleaned_df_with_IMDB[cleaned_df_with_IMDB[\"imdb_id\"].isna()]\n",
    "print(missing_ids.shape)\n",
    "missing_ids.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unfortunately some of the titleTypes are mislabled too.... GHAAAD\n",
    "# # Will use this later once efficiency is improved on previous function\n",
    "\n",
    "\n",
    "# imdb_df_2 = pd.read_feather(\"data/imdb_df_full.feather\")\n",
    "# imdb_df_2.rename(columns={\"startYear\": \"releaseYear\", \"primaryTitle\": \"title\", \"averageRating\": \"imdbRating\"}, inplace=True)\n",
    "# imdb_df_2[\"titleCleaned\"] = imdb_df_2[[\"title\"]].applymap(tocleanstring)\n",
    "# imdb_df_2 = imdb_df_2[\n",
    "#     (imdb_df_2[\"titleType\"] == \"short\") |\n",
    "#     (imdb_df_2[\"titleType\"] == \"tvShort\") |\n",
    "#     (imdb_df_2[\"titleType\"] == \"tvMovie\") |\n",
    "#     (imdb_df_2[\"titleType\"] == \"tvMiniSeries\") |\n",
    "#     (imdb_df_2[\"titleType\"] == \"tvSpecial\") |\n",
    "#     (imdb_df_2[\"titleType\"] == \"video\") |\n",
    "#     (imdb_df_2[\"titleType\"] == \"tvPilot\")\n",
    "#     ].copy()\n",
    "# imdb_df_2.replace('\\\\N', np.NaN, inplace=True)\n",
    "# imdb_df_2.reset_index(drop=True, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34d53fb98219b7aa297780c5531bf6cf37a7200fceb7198a7dbad2919af90897"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
